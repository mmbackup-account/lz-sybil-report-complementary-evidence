# LAYER 0 sybil report complementary evidence

* Commonwealth report: [https://commonwealth.im/layerzero/discussion/22182-sybil-analysis-detailed-report-from-github-issue-1131](https://commonwealth.im/layerzero/discussion/22182-sybil-analysis-detailed-report-from-github-issue-1131)
* Github issue ID: #1131

## Overview

This complementary report contains airdrop cluster data with: 
1. The mapping from address-cluster to their corresponding arkham visualization url: [google drive url](https://drive.google.com/file/d/1lFfiGz3aegfvPybIapUQI5HxGn9RU5Zt/view?usp=sharing)
2. The mapping from address-cluster to the consolidation tx hash linking the `from` address to the cluster identified: [google drive url](https://drive.google.com/drive/folders/1cH1K7vcYuFjbLL1_U8p_qNGV2exNlpjd?usp=sharing)

We mapped this information ___for the 20 biggest airdrops___ we track. 

Out of the initial 210,188 distinct addresses and 341,562 address-cluster combination submitted, this complementary report covers:
* 198,430 distinct addresses (94.4% of total)
* and 312,043 address-cluster combinations (91.4% of total)

This aims to make the job of LayerZero teams easier to judge on whether our methodology is conclusive.

## Context

Our Sybil report combines data from 100+ airdrops to identify which addresses have consolidated airdrop proceeds after claiming an airdropped token. Subsequentely, we identify clusters for each airdrop: if A and B claimed the Arbitrum airdrop and sent the proceeds to C, then (A,B,C) is an Arbitrum airdrop farming cluster belonging to the same person.

Our airdrop farming database associates each address with a `cluster_id` that follows this labeling rule: `{protocol}_{chain slug}_{nonce}`. In our previous example, wallets A, B and C would be labeled as below in our database:

| Address | cluster_id |
| --- | --- |
| A | `arbitrum_arbitrum_1234` |
| B | `arbitrum_arbitrum_1234` |
| C | `arbitrum_arbitrum_1234` |

We can derive a unified cluster to link wallets that have been identified as airdrop farmers under several previous airdrops. To take our previous example, if we have: 

| Address | cluster_id |
| --- | --- |
| A | `arbitrum_arbitrum_1234` |
| B | `arbitrum_arbitrum_1234` |
| C | `arbitrum_arbitrum_1234` |
| B | `polyhedra_eth_9876` |
| D | `polyhedra_eth_9876` |

Then we prove that (A,B,C,D) are part of the same cluster and owned by the same entity. 

## How to check the sybil clusters we flagged

### Manipulating the provided data

We uploaded a flattened file of address to cluster [here](https://drive.google.com/file/d/1lFfiGz3aegfvPybIapUQI5HxGn9RU5Zt/view?usp=sharing). The granularity of the data is at `address`, `cluster_id` level, which means that some addresses will appear more than once (those that have farmed more than 1 airdrop). All of the clusters have their corresponding arkham url that you can visit to check the tx data for the cluster. 

__Example:__

We want to check that address `0x5ea31fe5878f2cfc904c779b0949aade53aec967` is indeed part of an airdrop farming cluster for the ArbDoge AI ($AIDOGE on Arbitrum) airdrop. 

![Sybil data Excel view](https://i.ibb.co/2jdWrdL/excel-1.png "Sybil Data").

We visit the provided arkham URL for the cluster `aidoge_arbitrum_31` : [https://platform.arkhamintelligence.com/visualizer/entity/0x44202ef00bfdeca17baa2e1ee1a92bc448f575ae?flow=all&positions=%7B%7D&sortDir=desc&sortKey=time&tokens=arbdoge-ai&usdGte=0.1
](https://platform.arkhamintelligence.com/visualizer/entity/0x44202ef00bfdeca17baa2e1ee1a92bc448f575ae?flow=all&positions=%7B%7D&sortDir=desc&sortKey=time&tokens=arbdoge-ai&usdGte=0.1
)

In case nothing shows up, it could be due to Arkham not tracking prices: in this case, remove the >= $0.1 filter on the transactions. 

![Arkham remove 0.1 USD filter](https://i.ibb.co/zGwfXY7/arkham-screenshot-1.png "Arkham remove 0.1 USD filter")

Once you have the Arkham visualization, you can see the cluster:

![Arkham ArbDoge AI cluster #31](https://i.ibb.co/LZ5SZ1J/arkham-screenshot-2.png "Arkham ArbDoge AI cluster #31")

The visualization URLs are generated by visualizing the token movements to and from the core address(es) of the cluster. A simple way to make sure our address `0x5ea31fe5878f2cfc904c779b0949aade53aec967` is in the cluster, we can just add it to the visualized entities in the upper-left search bar:

![Arkham ArbDoge AI cluster #31 search](https://i.ibb.co/cyf2gNP/arkham-screenshot-3.png "Arkham ArbDoge AI cluster #31 search")

Thus we can confirm that `0x5ea31fe5878f2cfc904c779b0949aade53aec967` is part of the cluster as it has sent ArbDoge to the cluster core node after claiming the airdrop:

![Arkham ArbDoge AI cluster #31 including 0x5ea31fe5878f2cfc904c779b0949aade53aec967](https://i.ibb.co/cycT92M/arkham-screenshot-4.png "Arkham ArbDoge AI cluster #31 including 0x5ea31fe5878f2cfc904c779b0949aade53aec967")

We can also lookup the consolidation transaction hash in the `consolidation_txs.csv` file located [here](https://drive.google.com/drive/folders/1cH1K7vcYuFjbLL1_U8p_qNGV2exNlpjd?usp=sharing). We find the corresponding [tx hash](https://arbiscan.io/tx/0xe82a820169ee800c342d85471310e5911be3d65804b33f21bc6984d11f780080
) where `0x5ea31fe5878f2cfc904c779b0949aade53aec967` sent \~217B $AIDOGE to `0x44202Ef00BfDeCA17baA2e1eE1a92bC448f575Ae`. Inspecting `0x44202Ef00BfDeCA17baA2e1eE1a92bC448f575Ae`, we will find that they received $AIDOGE from multiple addresses, before dumping them.

![Arbiscan ERC20 transfers related to 0x44202Ef00BfDeCA17baA2e1eE1a92bC448f575Ae](https://i.ibb.co/h9fyNMY/arbiscan-aidoge-1.png "Arbiscan ERC20 transfers related to 0x44202Ef00BfDeCA17baA2e1eE1a92bC448f575Ae")


### Known issues

There are known issues on Arkham's side for the following tokens where the data simply doesn't display: 
* Renzo
* AISHIB
* Omni Network

Also, some visualization urls might be too long, generating errors.

To cope with this, lookup the consolidation transaction hashes stored at [this Google Drive location](https://drive.google.com/drive/folders/1cH1K7vcYuFjbLL1_U8p_qNGV2exNlpjd?usp=sharing).

## How can I reproduce the cluster unification process?

The python code below will generate the unified clusters from the list of address - cluster_id

```
import networkx as nx 
import pandas as pd

df = pd.read_csv('FLATTENED_CSV_FILEPATH')

G = nx.from_pandas_edgelist(
    df,
    'address', 
    'cluster_id',
    create_using=nx.Graph()
)

# Find strongly connected components (clusters) in the graph
clusters = sorted(nx.connected_components(G), key=len, reverse=True)

cluster_mapping = {}
for i, cluster in enumerate(clusters):
    for user in cluster:
        cluster_mapping[user] = i + 1
            
df['unified_cluster'] = df.address.map(cluster_mapping)
```

